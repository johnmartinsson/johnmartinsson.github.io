<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>John Martinsson's Research Page</title>
<link rel="stylesheet" href="/styles.css">
<link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
<link rel="alternate" type="application/rss+xml" title="John Martinsson's Blog" href="/rss.xml">
<!-- Matomo -->
<script>
    // Privacy and GDPR friendly web-analytics
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
    var u="https://johnmartinsson.matomo.cloud/";
    _paq.push(['setTrackerUrl', u+'matomo.php']);
    _paq.push(['setSiteId', '1']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.async=true; g.src='https://cdn.matomo.cloud/johnmartinsson.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
    })();
</script>
<!-- End Matomo Code -->
</head>
<body>
    <div class="container">
        <header>
    <!-- Banner Image -->
    <div class="banner">
        <img src="/images/bioacoustics_cropped_2.png" alt="Banner Image" class="banner-image">
    </div>
    
    <!-- Profile Section -->
    <div class="profile-section">
        <div class="icon-group left">
            <a href="#" class="icon" onclick="togglePlayPause('sound1', this)">
                <span class="play-pause-icon play"></span>
                <img src="/images/vocalizing_bird_1.png" alt="Icon 1">
            </a>
            <a href="#" class="icon" onclick="togglePlayPause('sound2', this)">
                <span class="play-pause-icon play"></span>
                <img src="/images/vocalizing_frog_1.png" alt="Icon 2">
            </a>
            <a href="#" class="icon" onclick="togglePlayPause('sound3', this)">
                <span class="play-pause-icon play"></span>
                <img src="/images/vocalizing_whale.png" alt="Icon 3">
            </a>
        </div>
        <img src="/images/profile_photo.png" alt="Profile Picture" class="profile-photo">
        <div class="icon-group right">
            <a href="#" class="icon" onclick="togglePlayPause('sound4', this)">
                <span class="play-pause-icon play"></span>
                <img src="/images/vocalizing_bird_2.png" alt="Icon 4">
            </a>
            <a href="#" class="icon" onclick="togglePlayPause('sound5', this)">
                <span class="play-pause-icon play"></span>
                <img src="/images/vocalizing_wolf.png" alt="Icon 5">
            </a>
            <a href="#" class="icon" onclick="togglePlayPause('sound6', this)">
                <span class="play-pause-icon play"></span>
                <img src="/images/vocalizing_frog_2.png" alt="Icon 6">
            </a>
        </div>
    </div>

    <!-- Audio elements -->
    <audio id="sound1" src="/audio/bird_1_short.mp3"></audio>
    <audio id="sound2" src="/audio/frog_1_short.mp3"></audio>
    <audio id="sound3" src="/audio/whale_short.mp3"></audio>
    <audio id="sound4" src="/audio/bird_2_short.mp3"></audio>
    <audio id="sound5" src="/audio/wolf_short.mp3"></audio>
    <audio id="sound6" src="/audio/frog_2_short.mp3"></audio>

    <!-- Name and socials -->
    <h1>John Martinsson</h1>
    <div class="social-links">
        <div class="social-link">
            <a href="https://github.com/johnmartinsson" target="_blank" aria-label="GitHub">
                <svg xmlns="http://www.w3.org/2000/svg" width="1.5em" height="1.5em" viewBox="0 0 24 24"><path fill="currentColor" d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
                <span>GitHub</span>
            </a>
        </div>
        <div class="social-link">
            <a href="https://scholar.google.se/citations?hl=sv&user=sAMIwlMAAAAJ&view_op=list_works&sortby=pubdate" target="_blank" aria-label="Google Scholar">
                <svg xmlns="http://www.w3.org/2000/svg" width="1.5em" height="1.5em" viewBox="0 0 24 24"><path fill="currentColor" d="M5.242 13.769L0 9.5L12 0l12 9.5l-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269M12 10a7 7 0 1 0 0 14a7 7 0 0 0 0-14"/></svg>
                <span>Google Scholar</span>
            </a>
        </div>
        <div class="social-link">
            <a href="https://bsky.app/profile/johnmartinsson.bsky.social" target="_blank" aria-label="Bluesky">
                <svg xmlns="http://www.w3.org/2000/svg" width="1.5em" height="1.5em" viewBox="0 0 24 24"><path fill="currentColor" d="M12 11.388c-.906-1.761-3.372-5.044-5.665-6.662c-2.197-1.55-3.034-1.283-3.583-1.033C2.116 3.978 2 4.955 2 5.528c0 .575.315 4.709.52 5.4c.68 2.28 3.094 3.05 5.32 2.803c-3.26.483-6.157 1.67-2.36 5.898c4.178 4.325 5.726-.927 6.52-3.59c.794 2.663 1.708 7.726 6.444 3.59c3.556-3.59.977-5.415-2.283-5.898c2.225.247 4.64-.523 5.319-2.803c.205-.69.52-4.825.52-5.399c0-.575-.116-1.55-.752-1.838c-.549-.248-1.386-.517-3.583 1.033c-2.293 1.621-4.76 4.904-5.665 6.664"/></svg>
                <span>Bluesky</span>
            </a>
        </div>
    </div>
</header>
        <main>
            

<section class="research_vision">
    <!-- Research vision -->
    <h2>Machine Listening for Bioacoustics</h2>
    <p>
        My research interests lie in applying machine learning to automated sensing and perception of natural environments, particularly through sound. I aim to develop machine listening methods that help monitor the impacts humans have on ecosystems by enabling automated species detection and biodiversity estimation in bioacoustic data.
    </p>
    <div class="section-header">
        <img src="/images/automated_habitat_monitoring_colorized.png" alt="Automated habitat monitoring and the effect of human interventions.">
    </div>
    <p>
        I am particularly interested in annotation-efficient machine listening methods for bioacoustics and ecoacoustics. I believe there is immense potential in using acoustic sensors and machine listening techniques to quantify the state of our natural environment, especially for monitoring animal populations.
    </p>
    <div class="section-header">
        <img src="/images/machine_learning_for_habitat_monitoring_colorized.png" alt="Automated analysis of acoustic and visual sensor data using machine learning.">
    </div>
    <p>
        The information in sound is often complementary to that of images, and the combination of the two can give a more complete understanding of the environment. While larger animals such as the fox may be easier to capture on camera, smaller but acoustically active animals like birds and frogs may be easier to capture with a microphone. I am excited about the possibilities of combining acoustic and visual sensor data to monitor ecosystems and the effects of human interventions.
    </p>
    <!-- AI-generated podcast -->
    <h2>Listen to This AI-Generated Podcast</h2>
    <p>
        I prompted NotebookLM with the text above to generate a short podcast about my research vision. It offers an engaging listen and captures my aspirations for machine listening in bioacoustics quite well. While my contributions to the field are exaggerated, it serves as a fun experiment in AI-generated content.
    </p>

    <audio controls>
        <source src="/audio/about-me.wav" type="audio/wav">
      Your browser does not support the audio element.
    </audio>

    <!-- People I work with -->
    <h2>People I Work With</h2> 
    <p>
        I am a PhD student at RISE working in the <a href="https://dl-group.se/">deep learning group</a>, and affiliated with Lund University. My supervisors are <a href="https://mogren.one">Olof Mogren</a> and <a href="https://www.maths.lu.se/english/research/staff/mariasandsten/">Maria Sandsten</a>. After a 2-month research visit at the <a href="https://webpages.tuni.fi/arg/">audio research group</a> at Tampere University, I have also been collaborating with <a href="https://homepages.tuni.fi/tuomas.virtanen/">Tuomas Virtanen</a>.
    </p>

    <!-- Selected publications -->
    <h2>Selected Publications</h2>
    <p>
        A selection of publications related to machine listening, bioacoustics, and environmental monitoring. You can find all my publications on <a href="https://scholar.google.se/citations?hl=sv&user=sAMIwlMAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Google Scholar</a>.
    </p>

    <ul class="publications-list">
        <li>
            <strong>J. Martinsson</strong>, O. Mogren, M. Sandsten, and T. Virtanen, <a href="https://doi.org/10.23919/EUSIPCO63174.2024.10715098" target="_blank">"From Weak to Strong Sound Event Labels using Adaptive Change-Point Detection and Active Learning"</a>, <em>2024 32nd European Signal Processing Conference (EUSIPCO)</em>, Lyon, France, 2024 (nominated for best student paper).
        </li>
        <li>
            <strong>J. Martinsson</strong>, M. Willbo, A. Pirinen, O. Mogren, and M. Sandsten, <a href="https://dcase.community/documents/workshop2022/proceedings/DCASE2022Workshop_Martinsson_13.pdf" target="_blank">"Few-shot bioacoustic event detection using an event-length adapted ensemble of prototypical networks"</a>, <em>Proceedings of the 7th Workshop on Detection and Classification of Acoustic Scenes and Events (DCASE 2022)</em>, Nancy, France, 2022.
        </li>
        <li>
            <strong>J. Martinsson</strong>, <a href="https://lucris.lub.lu.se/ws/portalfiles/portal/195517213/Lic_avhandling_John_Martinsson_LUCRIS.pdf" target="_blank">"Efficient and precise annotation of local structures in data"</a>, <em>Centre for Mathematical Sciences, Lund University</em>, Lund, Sweden, 2024 (licentiate thesis).
        </li>
        <li>
            D. Glebe, T. Johansson, <strong>J. Martinsson</strong>, and A. Genell, <a href="http://urn.kb.se/resolve?urn=urn:nbn:se:naturvardsverket:diva-10416" target="_blank">"Bullerdatainsamling och autonom artidentifiering för att underlätta miljöövervakning: En syntes"</a>(English title: "Noise Data Collection and Autonomous Species Identification to Facilitate Environmental Monitoring: A Synthesis"), <em>Naturvårdsverket</em>, Stockholm, 2022.
        </li>
        <li>
            <strong>J. Martinsson</strong> and M. Sandsten, <a href="https://doi.org/10.1109/ICASSP48485.2024.10446816" target="_blank">"DMEL: The Differentiable Log-Mel Spectrogram as a Trainable Layer in Neural Networks"</a>, <em>ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, Seoul, South Korea, 2024.
        </li>
        <li>
            <strong>J. Martinsson</strong>, M. Runefors, H. Frantzich, D. Glebe, M. McNamee, and O. Mogren, <a href="https://doi.org/10.1007/s10694-022-01307-1" target="_blank">"A Novel Method for Smart Fire Detection Using Acoustic Measurements and Machine Learning: Proof of Concept"</a>, <em>Fire Technol</em>, vol. 58, 2022 (best paper award).
        </li>

        <!-- Add more publications here -->
    </ul>
</section>
        </main>
        <footer>
    <div class="footer-container">
        <div class="social-links">
            <div class="social-link">
                <a href="https://github.com/johnmartinsson" target="_blank" aria-label="GitHub">
                    <svg xmlns="http://www.w3.org/2000/svg" width="1.5em" height="1.5em" viewBox="0 0 24 24"><path fill="currentColor" d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
                </a>
            </div>
            <div class="social-link">
                <a href="https://scholar.google.se/citations?hl=sv&user=sAMIwlMAAAAJ&view_op=list_works&sortby=pubdate" target="_blank" aria-label="Google Scholar">
                    <svg xmlns="http://www.w3.org/2000/svg" width="1.5em" height="1.5em" viewBox="0 0 24 24"><path fill="currentColor" d="M5.242 13.769L0 9.5L12 0l12 9.5l-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269M12 10a7 7 0 1 0 0 14a7 7 0 0 0 0-14"/></svg>
                </a>
            </div>
            <div class="social-link">
                <a href="https://bsky.app/profile/johnmartinsson.bsky.social" target="_blank" aria-label="Bluesky">
                    <svg xmlns="http://www.w3.org/2000/svg" width="1.5em" height="1.5em" viewBox="0 0 24 24"><path fill="currentColor" d="M12 11.388c-.906-1.761-3.372-5.044-5.665-6.662c-2.197-1.55-3.034-1.283-3.583-1.033C2.116 3.978 2 4.955 2 5.528c0 .575.315 4.709.52 5.4c.68 2.28 3.094 3.05 5.32 2.803c-3.26.483-6.157 1.67-2.36 5.898c4.178 4.325 5.726-.927 6.52-3.59c.794 2.663 1.708 7.726 6.444 3.59c3.556-3.59.977-5.415-2.283-5.898c2.225.247 4.64-.523 5.319-2.803c.205-.69.52-4.825.52-5.399c0-.575-.116-1.55-.752-1.838c-.549-.248-1.386-.517-3.583 1.033c-2.293 1.621-4.76 4.904-5.665 6.664"/></svg>
                </a>
            </div>
        </div>
    </div>
    <p>&copy; 2024 John Martinsson. All rights reserved.</p>
</footer>
    </div>
    <script src="script.js"></script>
</body>
</html>