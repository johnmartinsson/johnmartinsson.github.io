---
filename: index.html
title: John Martinsson's Research and Blog 
description: John Martinsson's research and blog on machine listening for bioacoustics.
---

<section class="research_vision">
    <!-- Research vision -->
    <h2>Machine Listening for Bioacoustics</h2>
    <p>
        My research interests lie in applying machine learning to automated sensing and perception of natural environments, particularly through sound. I aim to develop machine listening methods that help monitor the impacts humans have on ecosystems by enabling automated species detection and biodiversity estimation in bioacoustic data.
    </p>
    <div class="section-header">
        <img src="/images/automated_habitat_monitoring_colorized.webp" alt="Automated habitat monitoring and the effect of human interventions." loading="lazy">
    </div>
    <p>
        I am particularly interested in annotation-efficient machine listening methods for bioacoustics and ecoacoustics. I believe there is immense potential in using acoustic sensors and machine listening techniques to quantify the state of our natural environment, especially for monitoring animal populations.
    </p>
    <div class="section-header">
        <img src="/images/machine_learning_for_habitat_monitoring_colorized.webp" alt="Automated analysis of acoustic and visual sensor data using machine learning." loading="lazy">
    </div>
    <p>
        The information in sound is often complementary to that of images, and the combination of the two can give a more complete understanding of the environment. While larger animals such as the fox may be easier to capture on camera, smaller but acoustically active animals like birds and frogs may be easier to capture with a microphone. I am excited about the possibilities of combining acoustic and visual sensor data to monitor ecosystems and the effects of human interventions.
    </p>
    <!-- AI-generated podcast -->
    <h2>Listen to This AI-Generated Podcast</h2>
    <p>
        I prompted NotebookLM with the text above to generate a short podcast about my research vision. It offers an engaging listen and captures my aspirations for machine listening in bioacoustics quite well. While my contributions to the field are exaggerated, it serves as a fun experiment in AI-generated content.
    </p>

    <audio controls>
        <source src="/audio/about-me.webm" type="audio/wav">
      Your browser does not support the audio element.
    </audio>

    <!-- People I work with -->
    <h2>People I Work With</h2> 
    <p>
        I am a PhD student at RISE working in the <a href="https://dl-group.se/">deep learning group</a>, and affiliated with Lund University. My supervisors are <a href="https://mogren.one">Olof Mogren</a> and <a href="https://www.maths.lu.se/english/research/staff/mariasandsten/">Maria Sandsten</a>. After a 2-month research visit at the <a href="https://webpages.tuni.fi/arg/">audio research group</a> at Tampere University, I have also been collaborating with <a href="https://homepages.tuni.fi/tuomas.virtanen/">Tuomas Virtanen</a>.
    </p>

    <!-- Selected publications -->
    <h2>Selected Publications</h2>
    <p>
        A selection of publications related to machine listening, bioacoustics, and environmental monitoring. You can find all my publications on <a href="https://scholar.google.se/citations?hl=sv&user=sAMIwlMAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Google Scholar</a>.
    </p>

    <ul class="publications-list">
        <li>
            <strong>J. Martinsson</strong>, O. Mogren, M. Sandsten, and T. Virtanen, <a href="https://doi.org/10.23919/EUSIPCO63174.2024.10715098" target="_blank">"From Weak to Strong Sound Event Labels using Adaptive Change-Point Detection and Active Learning"</a>, <em>2024 32nd European Signal Processing Conference (EUSIPCO)</em>, Lyon, France, 2024 (nominated for best student paper).
        </li>
        <li>
            <strong>J. Martinsson</strong>, M. Willbo, A. Pirinen, O. Mogren, and M. Sandsten, <a href="https://dcase.community/documents/workshop2022/proceedings/DCASE2022Workshop_Martinsson_13.pdf" target="_blank">"Few-shot bioacoustic event detection using an event-length adapted ensemble of prototypical networks"</a>, <em>Proceedings of the 7th Workshop on Detection and Classification of Acoustic Scenes and Events (DCASE 2022)</em>, Nancy, France, 2022.
        </li>
        <li>
            <strong>J. Martinsson</strong>, <a href="https://lucris.lub.lu.se/ws/portalfiles/portal/195517213/Lic_avhandling_John_Martinsson_LUCRIS.pdf" target="_blank">"Efficient and precise annotation of local structures in data"</a>, <em>Centre for Mathematical Sciences, Lund University</em>, Lund, Sweden, 2024 (licentiate thesis).
        </li>
        <li>
            D. Glebe, T. Johansson, <strong>J. Martinsson</strong>, and A. Genell, <a href="http://urn.kb.se/resolve?urn=urn:nbn:se:naturvardsverket:diva-10416" target="_blank">"Bullerdatainsamling och autonom artidentifiering för att underlätta miljöövervakning: En syntes"</a>(English title: "Noise Data Collection and Autonomous Species Identification to Facilitate Environmental Monitoring: A Synthesis"), <em>Naturvårdsverket</em>, Stockholm, 2022.
        </li>
        <li>
            <strong>J. Martinsson</strong> and M. Sandsten, <a href="https://doi.org/10.1109/ICASSP48485.2024.10446816" target="_blank">"DMEL: The Differentiable Log-Mel Spectrogram as a Trainable Layer in Neural Networks"</a>, <em>ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, Seoul, South Korea, 2024.
        </li>
        <li>
            <strong>J. Martinsson</strong>, M. Runefors, H. Frantzich, D. Glebe, M. McNamee, and O. Mogren, <a href="https://doi.org/10.1007/s10694-022-01307-1" target="_blank">"A Novel Method for Smart Fire Detection Using Acoustic Measurements and Machine Learning: Proof of Concept"</a>, <em>Fire Technol</em>, vol. 58, 2022 (best paper award).
        </li>

        <!-- Add more publications here -->
    </ul>
</section>